{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29840f73",
   "metadata": {},
   "source": [
    "# Тестовое задание.\n",
    "\n",
    "## Devim.\n",
    "\n",
    "## Daudov Vagiz.\n",
    "\n",
    "Отчет на тестовое задание.\n",
    "\n",
    "Доступ ко всему коду и материалам доступен по ссылке на GitHub: https://github.com/vagizD/credit-predictions\n",
    "\n",
    "\n",
    "## 1. Цель проекта.\n",
    "\n",
    "Сравнить распределение каждого признака на выборке выданных кредитов (bad !=\n",
    "nan) с распределением этого же признака на всей выборке. Прокомментировать\n",
    "причину различий. Дополнить комментарии графиками, выбрав 4-5 показательных\n",
    "признаков. Если есть признаки, между которыми различий в распределении не\n",
    "наблюдается, объяснить причину.\n",
    "\n",
    "Обучить модель классификации только на выданных кредитах, целевая переменная\n",
    "bad. Придумать/найти алгоритм разметки отклоненных (bad=NaN) заявок. После\n",
    "применения алгоритма разметки, обучить модель классификации на всех заявках.\n",
    "Сравнить с моделью, обученной только на выданных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71c5784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main libraries\n",
    "import sklearn\n",
    "import catboost\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Process\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Saving in binary\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a45e758",
   "metadata": {},
   "source": [
    "## 2. Анализ данных.\n",
    "\n",
    "### 2.1.  Тепловая карта.\n",
    "\n",
    "Первым шагом анализа является просмотр наличия линейных зависимостей между данными. Это было выполнено с помощью тепловой карты (на выборке значений **bad!=nan**):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92c9aea",
   "metadata": {},
   "source": [
    "![Heatmap](heatmaps/whole-dataset-corr-mat-heatmap.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ccd7cf",
   "metadata": {},
   "source": [
    "Как можно заметить, переменная bad не имеет линейного коэффициента зависимости больше, чем 0.08. Это означает, что линейные модели не смогут адекватно работать с данной выборкой данных. Это можно проверить на примере Логистической Регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dff8cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing simple LogisticRegression\n",
    "np.random.seed(4)\n",
    "\n",
    "lr = LogisticRegression(max_iter=300)\n",
    "\n",
    "shuffled_df = df.dropna().drop(['region', 'approved', 'work_code'], axis=1).sample(frac=1)\n",
    "\n",
    "X = shuffled_df.drop(['bad'], axis=1)\n",
    "y = shuffled_df['bad']\n",
    "\n",
    "scaler = StandardScaler(with_mean=True,\n",
    "                        with_std=True).fit(X)\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "y_preds = lr.predict(X_test)\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7ab73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.76      1.00      0.86      1103\n",
    "         1.0       0.00      0.00      0.00       351\n",
    "\n",
    "    accuracy                           0.76      1454\n",
    "   macro avg       0.38      0.50      0.43      1454\n",
    "weighted avg       0.58      0.76      0.65      1454"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2118e66",
   "metadata": {},
   "source": [
    "Результаты репорта показали, что модель **не может определить** значения bad=1 (просроченные кредиты). Она имеет точность 76% (это число может варироваться +- 3-4% в зависимости от разделения `sklearn.metrics.train_test_split`) потому, что предсказывает все значения целевой переменной bad=0 (каждый клиент вернет кредит). Процент содержания нулей в целевой переменной составляет те самые 73%.\n",
    "\n",
    "### 2.2. Распределение данных.\n",
    "\n",
    "После просмотра линейных коэффициентов, требуется проследить изменения **распределений** каждой переменной между всей выборкой и выборкой со значениями bad!=NaN.\n",
    "\n",
    "Как показали результаты, переменные `bank_inqs_count_quarter`, `month_income`, `all_creds_count_lm`, `mfo_cred_mean_sum_3lm`, и `cred_day_overdue_all_sum_all` имеют самые значимые изменения в распределении.\n",
    "\n",
    "Их вероятностные графики (слева представлена вся выборка, справа - только по выданным кредитам):\n",
    "\n",
    "1. `bank_inqs_count_quarter`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bad110",
   "metadata": {},
   "source": [
    "![bank_inqs_count_quarter](distributions/4-bank_inqs_count_quarter-distribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa1e8d",
   "metadata": {},
   "source": [
    "Рапределение справа похоже на **распределение Гаусса**, что очень полезно для моделей наподобии `RandomForestClassifier`. Также, происходит смещение среднего значения (см. *заметка*). Люди, которые подают больше заявок в банк, чаще получают кредит от МФО.\n",
    "\n",
    "Заметка ( * ) : Оно происходит на изменении распреления каждой переменной потому, что люди, которым выдают кредит, имеют более высокие шансы его вернуть, чем те, кому не выдают кредит. Это исходит из того факта, что решение выдать или не выдать кредит происходит **не случайно**, а решается людьми, которые имеют опыт в определении этой вероятности в жизни. Они также оценивают потенциального клиента на основе его зарплаты, кредитной истории, взятых кредитов на данный момент и тд - все переменные задания - на основе своего опыта работы с клиентами. Таким образом, например, люди, которым выдали кредит, имеют в **среднем большую** зарплату, чем основная выборка. Сравнивая только тех, кому **не выдали кредит**, и тех, кому выдали, проследить изменение было бы еще более явно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150760e7",
   "metadata": {},
   "source": [
    "2. `month_income`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bef02d1",
   "metadata": {},
   "source": [
    "![month_income](distributions/21-month_income-distribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9e439a",
   "metadata": {},
   "source": [
    "График показывает изменения в высоте пиков и средней месячной зарплаты.\n",
    "\n",
    "3. `all_creds_count_lm`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a713d0",
   "metadata": {},
   "source": [
    "![all_creds_count_lm](distributions/19-all_creds_count_lm-distribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2bd428",
   "metadata": {},
   "source": [
    "График справа не имеет высокого пика в нуле, форма имеет необходимое распределение.\n",
    "\n",
    "4. `mfo_cred_mean_sum_3lm`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070e2b94",
   "metadata": {},
   "source": [
    "![mfo_cred_mean_sum_3lm](distributions/11-mfo_cred_mean_sum_3lm-distribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a03bc4",
   "metadata": {},
   "source": [
    "Пик почти совпадает со средним значением. Также, средняя сумма кредитов от МФО за последние три месяца почти в два раза выше справа.\n",
    "\n",
    "5. `cred_day_overdue_all_sum_all`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e31016",
   "metadata": {},
   "source": [
    "![cred_day_overdue_all_sum_all](distributions/14-cred_day_overdue_all_sum_all-distribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6eb014",
   "metadata": {},
   "source": [
    "Вместо биномиального распределения, здесь очень сильное изменение среднего значения, приблизительно 1300%. Это сопутствует изменению высоты пика, что очень сильно уменьшает среднее отклонение.\n",
    "\n",
    "\n",
    "Есть также переменные, в которых изменения в распределении **не наблюдается**. Например:\n",
    "\n",
    "6. `count_overdue_all_3lm`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350757ed",
   "metadata": {},
   "source": [
    "![count_overdue_all_3lm](distributions/18-count_overdue_all_3lm-distribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5e64e1",
   "metadata": {},
   "source": [
    "Два графика имеют практически идентичные средние значения и форму распределений. С большой вероятностью, это означает, что данная переменная не имеет важности в определении целевой переменной. Соответсвтенно, значимость для алгоритмов машинного обучения будет минимальная.\n",
    "\n",
    "## 2.3. Использование RandomForestClassifier.\n",
    "\n",
    "RFC является сильным алгоритмом классификации, который имеет возможность находить зависимости нелинейного рода, что является акутальной проблемой данной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63307f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing non-linear relationships\n",
    "np.random.seed(4)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=1000, random_state=4)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1445f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.7537826685006878"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9479bc6a",
   "metadata": {},
   "source": [
    "Визуализация важности переменных для RFC:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0ce81f",
   "metadata": {},
   "source": [
    "![feature-importances](feature-importances/feature-importances.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9c9235",
   "metadata": {},
   "source": [
    "Результаты, полученные с помощью данного метода, должны быть перепроверены, потому что для плохой модели определенные переменные могут иметь большую важность, а те же переменные для отличной модели - низкую (scikit-learn documentation). Для проверки потенциальной ошибки модели используется метод пермутации переменных:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b42838a",
   "metadata": {},
   "source": [
    "![feature-importances-permutation](feature-importances/feature-importances-permutation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef4270e",
   "metadata": {},
   "source": [
    "Как можно увилеть, модель очень не стабильна. Огромный процент переменных показывает положительное влияние на модель в одних случаях и отрицатльное в других. Данный этап можно попробовать обойти искуственно - с помощью техники `forward_feature_selection`. Она позволяет провести итеративное извлечение переменных и выдает лучший их сет.\n",
    "\n",
    "### 2.4. Forward feature selection.\n",
    "\n",
    "Главная метрика - `f1_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d405f81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metric(model, x_cv, y_cv):\n",
    "    return f1_score(y_cv, model.predict(x_cv), average='micro')\n",
    "\n",
    "\n",
    "def forward_feature_selection(x_train, x_cv, y_train, y_cv, n):\n",
    "    \"\"\"\n",
    "    Input : Dataframe df with m features, number of required features n\n",
    "    Output : Set of n features most useful for model performance\n",
    "    Decision function: f1_score\n",
    "    \"\"\"\n",
    "    feature_set = []\n",
    "    for num_features in range(n):\n",
    "        metric_list = []\n",
    "        model = RandomForestClassifier(n_estimators=1000,\n",
    "                                       random_state=4)\n",
    "        for feature in x_train.columns:\n",
    "            if feature not in feature_set:\n",
    "                f_set = feature_set.copy()\n",
    "                f_set.append(feature)\n",
    "                model.fit(x_train[f_set], y_train)\n",
    "                metric_list.append((evaluate_metric(model, x_cv[f_set], y_cv), feature))\n",
    "\n",
    "        metric_list.sort(key=lambda x : x[0], reverse = True)\n",
    "        feature_set.append(metric_list[0][1])\n",
    "    return feature_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4c80d3",
   "metadata": {},
   "source": [
    "Получив 15 лучших переменных из 21, RFC выдает следующий результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bec7a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing best features with previous rfc\n",
    "np.random.seed(4)\n",
    "\n",
    "X = shuffled_df[best_features]\n",
    "y = shuffled_df['bad']\n",
    "\n",
    "scaler = StandardScaler(with_mean=True,\n",
    "                        with_std=True).fit(X)\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "y_preds = rfc.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_preds))\n",
    "print(rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c356e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.73      0.98      0.84      1052\n",
    "         1.0       0.45      0.04      0.08       402\n",
    "\n",
    "    accuracy                           0.72      1454\n",
    "   macro avg       0.59      0.51      0.46      1454\n",
    "weighted avg       0.65      0.72      0.63      1454"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6945fbf",
   "metadata": {},
   "source": [
    "Иными словами, модель проваливает свою цель хоть как то определять bad=1 значения. Далее, был проведен ряд испытаний и изменений гиперпараметров в целях улучшения результата `recall_score` для 1.0. Однако, результат отсутствовал. Вне зависимости от числа переменных, самих переменных, и гиперпараметров, число `true positive` значений не превосходило 15% от общего числа bad=1 значений (и даже в этих случаях падал `precision` и `recall` отрицательного класса). Поиск `forward_feature_selection_3` c главной метрикой в виде `recall_score` не дало видимых улучшений. Единственное, был получен список переменных в порядке уменьшения значимости для RFC, который мог бы быть использован в дальнейшем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5590cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "['cred_sum_debt_all_all', 'month_income', 'delay_more_sum_all',\n",
    "'count_overdue_all_3lm', 'cred_sum_overdue_cc_all',\n",
    "'cred_max_overdue_max_3lm', 'cred_max_overdue_max_ly',\n",
    "'cred_day_overdue_all_sum_all', 'mfo_inqs_count_month',\n",
    "'work_code', 'all_creds_count_lm', 'all_active_creds_sum_all',\n",
    "'mfo_closed_count_ly', 'all_closed_creds_sum_ly',\n",
    "'bank_inqs_count_quarter', 'cred_sum_cc_ly', 'mfo_last_days_all']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eea1ff1",
   "metadata": {},
   "source": [
    "## 3. Моделирование 1.\n",
    "\n",
    "Ввиду отсутствия положитльных результатов RFC, было решено попробовать другую модель из библиотеки catboost - CatBoostClassifier (CBC). Именно эта модель была выбрана потому, что она имеет параметр автоматического балансирования классов, что бы подняло `recall_score` для 1.0. Была применена такая же техника `forward_feature_selection` с главной метрикой в виде максимального числа  `true positive (tp)` значений и получен следующий результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380a1394",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number of features: 16\n",
    "5-folded CV score: 64.239%\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.73      0.78      0.75      1041\n",
    "         1.0       0.33      0.28      0.30       413\n",
    "\n",
    "    accuracy                           0.63      1454\n",
    "   macro avg       0.53      0.53      0.53      1454\n",
    "weighted avg       0.62      0.63      0.62      1454"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdfa8af",
   "metadata": {},
   "source": [
    "`recall` положительного класса уже 28%, хоть и точность модели оставляет желать лучшего - 64%. Было решено остановиться на этой модели и провести подбор гиперпараметров для CBC используя `grid_search`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202c9e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4)\n",
    "\n",
    "X = df_nona[final_feats]\n",
    "\n",
    "y = df_nona['bad']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "final_model = CatBoostClassifier(loss_function='Logloss')\n",
    "\n",
    "grid = {\"learning_rate\": [0.5, 1, 1.5],\n",
    "        \"random_seed\": [4],\n",
    "        \"iterations\": [1000],\n",
    "        \"auto_class_weights\": ['Balanced'],\n",
    "        \"depth\": [4, 6, 8, 10],\n",
    "        \"l2_leaf_reg\": [1, 3, 5, 7, 9],\n",
    "        \"verbose\": [False]}\n",
    "\n",
    "final_model_tuning_1 = final_model.grid_search(param_grid=grid,\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            cv=5,\n",
    "            partition_random_seed=4,\n",
    "            calc_cv_statistics=False,\n",
    "            search_by_train_test_split=False,\n",
    "            refit=True,\n",
    "            shuffle=True,\n",
    "            stratified=None,\n",
    "            verbose=False,\n",
    "            plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d148aacb",
   "metadata": {},
   "source": [
    "Улучшения модели отсутствовали, поэтому было решено оставить начальные результаты CBC. Модель была протестирована на финальном сете данных `test.csv` и получены практически идентичные результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b7777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "X_last = test_data.dropna()[final_feats]\n",
    "y_last = test_data.dropna()['bad']\n",
    "\n",
    "y_preds = cat.predict(X_last)\n",
    "\n",
    "print(classification_report(y_last, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcca7021",
   "metadata": {},
   "outputs": [],
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.75      0.77      0.76       274\n",
    "         1.0       0.31      0.28      0.30        99\n",
    "\n",
    "    accuracy                           0.64       373\n",
    "   macro avg       0.53      0.53      0.53       373\n",
    "weighted avg       0.63      0.64      0.64       373"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f35286",
   "metadata": {},
   "source": [
    "## 4. Алгоритм замены bad=NaN значений.\n",
    "\n",
    "### 4.1. Гипотеза.\n",
    "\n",
    "1. Отклоненные заявки могут быть промаркерованы **двумя способами** - с помощью создания новой категории (или категорий), или используя те же 1 и 0 значения (по сути это означает предсказать, что если бы человек получил кредит, который ему не был одобрен, то просрочил бы он его или нет). Первый вариант заранее включает в себя предвзятость - **100% корреляция** с переменной `approved`, поэтому остается второй вариант.\n",
    "2. Для маркировки значений можно использовать имеющуюся модель и предсказать отсутствующие значения, но это заранее ставит определенные проблемы. Во-первых, CBC не обладает тем уровнем точности, чтобы адекватно предсказать значения, которые будут в дальнейшем использованы для тренировки другой модели. Во вторых, модель находит где то 25% bad=1 значений от всего количества, но это не просто другой датасет, в нем **изначально заложена другая информация** (как было упомянуто ранее в анализе распределений переменных): все значения bad=NaN (approved=0) уже решены на основе выборки данных. Этот датасет **должен** быть отличным от тренировочного датасета CBC потому, что он был отфильтрован людьми, которые решают, выдать кредит или нет (не радномное распределение переменной `approved`). Таким образом, **отношение bad=1/bad=0** должен быть не 27%/73%, а значитально выше.\n",
    "3. Представим, что имеется гиперфункция, которая определяет вероятность того, будет ли возвращен кредит или нет (нахождение такой гиперфункции означало бы успешное завершение проекта). Человек, который выдает кредит, решает, при каком пороге его решение меняется с \"выдать кредит\" на \"не выдавать кредит\". Этот порог зависит не только от самого человека, но и от других факторов тоже (финансовая ситуация, последние изменения в законах, и другие вещи, которые не могут сразу отразиться в работе гиперфункции). Это может быть 50%, 60%, 65%, или даже 90%. Какой же **вероятностный порог** нашей выборки? Назовем его **ВП**.\n",
    "4. Если известно отношение bad=1 значений к bad=0 значениям вместе с алгоритмом, определяющим эти значения, то можно вычислить ВП. Исходя из статистики, представленной в **пункте 2** (про отношение bad=1/bad=0 и 25% bad=1 значений), очевдино, что дефолтный порог в 50% (который стоит у моделей для определения бинарной классификации, также и у **CBC**) нужно поднять.\n",
    "5. Представим, что ВП=65%. Это означает, что средний процент вероятности на выборке таких клиентов будет приблизительно 75%-80% (+-15% как основное стандартное отклонение на отрезке [0.65, 1.0]). Если взять ситуацию с МФО, где **1 из 4** людей просрачивает кредит (согласно статистике из начального датасета), то порог уверенности в 65% как раз подходит.\n",
    "\n",
    "### 4.2. Использование гипотезы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8582b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_threshold(threshold):\n",
    "    np.random.seed(4)\n",
    "    \n",
    "    df_na = df.loc[df.bad.isna() == True]\n",
    "\n",
    "    X = df_na[final_feats]\n",
    "    \n",
    "    y_preds = cat.predict_proba(X)\n",
    "    \n",
    "    labels = []\n",
    "    for i in y_preds:\n",
    "        if i[0] > threshold:\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "    return pd.DataFrame(labels, columns=['bad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa9ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "Threshold is: 0.75\n",
    "bad\n",
    "0      8521\n",
    "1      7326\n",
    "dtype: int64\n",
    "0 to 1 ratio: 1.16\n",
    "Probability of bad=0: 0.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe16f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4)\n",
    "\n",
    "df_na = df.loc[df.bad.isna() == True]\n",
    "\n",
    "X = df_na[final_feats]\n",
    "\n",
    "y_preds = cat.predict_proba(X)\n",
    "\n",
    "labels = []\n",
    "for i in y_preds:\n",
    "    if i[0] > 0.75:\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)\n",
    "\n",
    "df_na['bad'] = labels\n",
    "\n",
    "df_full = pd.concat([df.dropna(), df_na])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e99fb6",
   "metadata": {},
   "source": [
    "## 5. Моделирование 2.\n",
    "\n",
    "Обучение CBC_2 на всей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40c0749",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4)\n",
    "\n",
    "cat_2 = CatBoostClassifier(learning_rate=1,\n",
    "                           random_seed=4,\n",
    "                           verbose=False,\n",
    "                           iterations=1000,\n",
    "                           auto_class_weights='Balanced',\n",
    "                           depth=8,\n",
    "                           l2_leaf_reg=3)\n",
    "\n",
    "X = df_full[final_feats]\n",
    "y = df_full['bad']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "cat_2.fit(X_train, y_train)\n",
    "print(classification_report(y_test, cat_2.predict(X_test)))\n",
    "print(np.mean(cross_val_score(cat_2, X_train, y_train, cv=5, verbose=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16e6574",
   "metadata": {},
   "outputs": [],
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.83      0.83      0.83      2790\n",
    "         1.0       0.74      0.74      0.74      1834\n",
    "\n",
    "    accuracy                           0.79      4624\n",
    "   macro avg       0.78      0.78      0.78      4624\n",
    "weighted avg       0.79      0.79      0.79      4624\n",
    "\n",
    "0.7862323891201208"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13864519",
   "metadata": {},
   "source": [
    "## 6. Сравнение моделирования 1 и моделирования 2.\n",
    "\n",
    "Тест моделей на всей выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd4356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC cat_1: 0.8988205657375812\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.89      0.98      0.93      2790\n",
    "         1.0       0.96      0.82      0.88      1834\n",
    "\n",
    "    accuracy                           0.92      4624\n",
    "   macro avg       0.93      0.90      0.91      4624\n",
    "weighted avg       0.92      0.92      0.91      4624\n",
    "\n",
    "AUC cat_2: 0.783397239713418\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.83      0.83      0.83      2790\n",
    "         1.0       0.74      0.74      0.74      1834\n",
    "\n",
    "    accuracy                           0.79      4624\n",
    "   macro avg       0.78      0.78      0.78      4624\n",
    "weighted avg       0.79      0.79      0.79      4624"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97c8b6",
   "metadata": {},
   "source": [
    "Тест моделей на финальной выборке `test.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97337da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "             precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.73      0.67      0.70        57\n",
    "         1.0       0.17      0.22      0.20        18\n",
    "\n",
    "    accuracy                           0.56        75\n",
    "   macro avg       0.45      0.44      0.45        75\n",
    "weighted avg       0.60      0.56      0.58        75\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.80      0.75      0.77        57\n",
    "         1.0       0.33      0.39      0.36        18\n",
    "\n",
    "    accuracy                           0.67        75\n",
    "   macro avg       0.56      0.57      0.57        75\n",
    "weighted avg       0.69      0.67      0.67        75\n",
    "\n",
    "AUC cat_1: 0.44444444444444453\n",
    "AUC cat_2: 0.5716374269005848"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae18ab13",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "1. Первая модель имеет 79% точность на выборке из bad=NaN значений, 92% точность на всей выборке, и 56% точность на финальной тестовой выборке (`recall`=0.22 положительного класса).\n",
    "2. Вторая модель имеет 79% точность на всей выборке и 67% точность на финальной тестовой выборке (`recall`=0.39 положительного класса, выше чем все предыдущие значения)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
